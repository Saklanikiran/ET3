{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b436ede-16ab-4dc5-8364-b496b99ed233",
   "metadata": {},
   "source": [
    "# Ans : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc484f7-57fd-4305-a518-eec7d0f264be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A Random Forest Regressor is an ensemble learning method for regression tasks that operates by constructing multiple decision trees during \n",
    "training and outputting the average prediction of the individual trees. This approach improves the model's accuracy and robustness by reducing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b802a3-d613-4d43-8e42-3b4a2039e429",
   "metadata": {},
   "source": [
    "# Ans : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152413ed-fd5d-405c-8e5d-eda96866978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Random Forest Regressor reduces overfitting by averaging the predictions of multiple decision trees, each trained on different subsets\n",
    "of the data. This ensemble method ensures that the model generalizes better to new, unseen data by minimizing the variance of the \n",
    "predictions.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a560e093-894b-4b1c-a205-323c7d5667e6",
   "metadata": {},
   "source": [
    "# Ans : 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc4488-a1b4-4335-8419-811eef2d8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The Random Forest Regressor aggregates predictions by taking the average of the outputs from all the individual decision trees.\n",
    "This averaging process helps to smooth out the predictions and improve the overall accuracy and stability of the model.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f09f51-c794-4d04-9ad0-668878c5e978",
   "metadata": {},
   "source": [
    "# Ans : 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a059f3-8c8f-44ba-87a9-4d23569fab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "n_estimators: The number of trees in the forest.\n",
    "max_depth: The maximum depth of the trees.\n",
    "min_samples_split: The minimum number of samples required to split an internal node.\n",
    "min_samples_leaf: The minimum number of samples required to be at a leaf node.\n",
    "max_features: The number of features to consider when looking for the best split.\n",
    "bootstrap: Whether bootstrap samples are used when building trees.\n",
    "random_state: Controls the randomness of the bootstrapping and feature selection.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1319a3cc-a6d9-466f-a5f6-3a88e9df1514",
   "metadata": {},
   "source": [
    "# Ans : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76449a56-e003-41c5-9a92-9031a81c972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The main difference is that a Decision Tree Regressor uses a single tree for making predictions, which can lead to overfitting and high \n",
    "variance. In contrast, a Random Forest Regressor uses an ensemble of multiple trees and averages their predictions, which reduces\n",
    "overfitting and improves generalization.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c64352-2abf-4607-809b-fc48dd4d1501",
   "metadata": {},
   "source": [
    "# Ans : 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a63b18-2237-4f0e-b33b-6a2826e2a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Advantages:\n",
    "\n",
    "Reduces overfitting compared to a single decision tree.\n",
    "Handles large datasets with higher dimensionality.\n",
    "Provides an estimate of feature importance.\n",
    "Works well with both numerical and categorical data.\n",
    "Disadvantages:\n",
    "\n",
    "Requires more computational resources and memory.\n",
    "Can be less interpretable than a single decision tree.\n",
    "Training time can be longer due to the construction of multiple trees.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5422834-7ed5-46ca-a629-f2552c38c4e4",
   "metadata": {},
   "source": [
    "# Ans : 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d710e6-f680-48df-95d6-efeb1ac7a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The output of a Random Forest Regressor is a continuous value, which is the average of the predictions made by all the individual decision trees in the forest.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b227725-1dec-4dfb-91f6-1513bc439f1a",
   "metadata": {},
   "source": [
    "# Ans : 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae58d931-20bb-415d-b7e2-7cb88d48a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Yes, the Random Forest algorithm can be used for classification tasks as well. When used for classification, it is called a Random Forest \n",
    "Classifier, and it operates by taking the majority vote of the predictions from all the individual trees.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
